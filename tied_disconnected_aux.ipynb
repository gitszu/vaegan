{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% load_ext autoreload \n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules_tied import VAE\n",
    "from modules_tied import NetD\n",
    "from modules_tied import Dummy\n",
    "from modules_tied import loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsz = 100\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=bsz, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=bsz, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = VAE()\n",
    "netD = NetD()\n",
    "dummy = Dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=1e-4)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=1e-4)\n",
    "optimizer_dummy = optim.Adam(dummy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(bsz,28,28)\n",
    "label = torch.FloatTensor(bsz)\n",
    "real_label=1\n",
    "fake_label=0\n",
    "USE_CUDA=1\n",
    "\n",
    "if(USE_CUDA):\n",
    "    netG=netG.cuda()\n",
    "    netD=netD.cuda()\n",
    "    #dummy=dummy.cuda()\n",
    "    criterion=criterion.cuda()\n",
    "    input,label=input.cuda(), label.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10000):\n",
    "    for i, (data,_) in enumerate(train_loader):\n",
    "        #update D: maximize log((D(x)) + log(1-D(G(z)))\n",
    "        netD.zero_grad()\n",
    "        #ummy.zero_grad()\n",
    "        \n",
    "        real_cpu = data\n",
    "        \n",
    "        if(USE_CUDA):\n",
    "            real_cpu = real_cpu.cuda()\n",
    "\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        label.resize_(bsz).fill_(real_label)\n",
    "\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        _,output = netD(inputv)\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        #train with fake\n",
    "        fake,mu,logvar = netG(inputv)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        _,output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        errD_fake.backward()\n",
    "\n",
    "       # zd = torch.FloatTensor(bsz,20).normal_(0,1).cuda()\n",
    "       # zd = Variable(zd)\n",
    "       # x_dummy = dummy(zd,netG)\n",
    "       # _,out_dummy = netD(x_dummy.detach())\n",
    "       # L_dummy = criterion(out_dummy, labelv)\n",
    "       # L_dummy.backward()\n",
    "        \n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake #+ L_dummy\n",
    "        optimizerD.step()\n",
    "\n",
    "        #step dummy\n",
    "        #x_dummy = dummy(zd,netG)\n",
    "        #_,out_dummy = netD(x_dummy.detach())\n",
    "        #labelv = Variable(label.fill_(real_label))\n",
    "        #LGAN_dummy = criterion(out_dummy,labelv)\n",
    "        #LGAN_dummy.backward()\n",
    "        #_,out_orig = netD(inputv)\n",
    "        #L_recon_dummy = loss_function(out_dummy.detach(),out_orig,mu.detach(),logvar.detach())\n",
    "        #L_recon_dummy.backward()\n",
    "        #optimizer_dummy.step()\n",
    "        \n",
    "        \n",
    "        # update G: maximize log((D(G(z))\n",
    "        if epoch%1==0:\n",
    "            netG.zero_grad()\n",
    "            labelv = Variable(label.fill_(real_label))\n",
    "            x_tilde, output = netD(fake)\n",
    "            x_l, output_orig = netD(inputv)\n",
    "            #errG = criterion(output,labelv) + loss_function(fake,inputv,mu,logvar)\n",
    "            #errG = loss_function(output,output_orig,mu,logvar) #+ 0.5*criterion(output,labelv)\n",
    "            #errG = #loss_function(fake,inputv,mu,logvar) +loss_function(output,output_orig,mu,logvar)\n",
    "            errG = loss_function(x_tilde,x_l,mu,logvar)\n",
    "            #errG = loss_function(fake,inputv,mu,logvar)\n",
    "\n",
    "            errG.backward()\n",
    "    \n",
    "            D_G_z2 = output.data.mean()\n",
    "            optimizerG.step()\n",
    "\n",
    "        if(epoch %1 ==0):\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, 100, i, len(train_loader),\n",
    "                     errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n",
    "            if i % 100 == 0:\n",
    "                print('real_cpu.size()', real_cpu.size())\n",
    "                vutils.save_image(real_cpu,\n",
    "                                  './real_samples.png',\n",
    "                                  normalize=True)\n",
    "                vutils.save_image(fake.data.view(-1,1,28,28),\n",
    "                                  './fake_samples.png',\n",
    "                                  normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
